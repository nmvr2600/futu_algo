#!/usr/bin/env python3
"""
ç¼ è®ºä¸­æ¢å’Œç´¢å¼•æ˜ å°„æµ‹è¯•å¥—ä»¶
æµ‹è¯•ä¸­æ¢è¯†åˆ«å’Œç´¢å¼•æ˜ å°„åŠŸèƒ½
"""

import pandas as pd
import numpy as np
import sys
import os
from typing import List, Tuple, Dict

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from util.chanlun import ChanlunProcessor, Central, Fractal, FractalType


class TestChanlunCentralMapping:
    """ç¼ è®ºä¸­æ¢å’Œç´¢å¼•æ˜ å°„æµ‹è¯•ç±»"""

    def __init__(self):
        self.processor = ChanlunProcessor()

    def create_central_test_data(self) -> pd.DataFrame:
        """åˆ›å»ºä¸­æ¢æµ‹è¯•æ•°æ®"""
        # åˆ›å»ºåŒ…å«æ˜æ˜¾ä¸­æ¢ç»“æ„çš„æ•°æ®
        days = 25
        data = {
            "time_key": pd.date_range("2024-01-01", periods=days, freq="D"),
            "open": [
                10.0,
                11.0,
                12.0,
                11.0,
                10.0,
                9.0,
                8.0,
                9.0,
                10.0,
                11.0,
                12.0,
                11.0,
                10.0,
                9.0,
                8.0,
                9.0,
                10.0,
                11.0,
                12.0,
                11.0,
                10.0,
                9.0,
                8.0,
                9.0,
                10.0,
            ],
            "high": [
                11.0,
                12.0,
                13.0,
                12.0,
                11.0,
                10.0,
                9.0,
                10.0,
                11.0,
                12.0,
                13.0,
                12.0,
                11.0,
                10.0,
                9.0,
                10.0,
                11.0,
                12.0,
                13.0,
                12.0,
                11.0,
                10.0,
                9.0,
                10.0,
                11.0,
            ],
            "low": [
                9.0,
                10.0,
                11.0,
                10.0,
                9.0,
                8.0,
                7.0,
                8.0,
                9.0,
                10.0,
                11.0,
                10.0,
                9.0,
                8.0,
                7.0,
                8.0,
                9.0,
                10.0,
                11.0,
                10.0,
                9.0,
                8.0,
                7.0,
                8.0,
                9.0,
            ],
            "close": [
                10.5,
                11.5,
                12.5,
                11.5,
                10.5,
                9.5,
                8.5,
                9.5,
                10.5,
                11.5,
                12.5,
                11.5,
                10.5,
                9.5,
                8.5,
                9.5,
                10.5,
                11.5,
                12.5,
                11.5,
                10.5,
                9.5,
                8.5,
                9.5,
                10.5,
            ],
        }
        return pd.DataFrame(data)

    def test_central_identification(self) -> bool:
        """æµ‹è¯•ä¸­æ¢è¯†åˆ«"""
        print("=== æµ‹è¯•ä¸­æ¢è¯†åˆ« ===")

        df = self.create_central_test_data()

        # æ‰§è¡Œå®Œæ•´çš„ç¼ è®ºå¤„ç†
        self.processor._merge_k_lines(df)
        fractals = self.processor.identify_fractals()
        strokes = self.processor.build_strokes()
        centrals = self.processor.build_centrals()

        print(f"åˆ†å‹: {len(fractals)}, ç¬”: {len(strokes)}, ä¸­æ¢: {len(centrals)}")

        # éªŒè¯ä¸­æ¢åŸºæœ¬å±æ€§
        for central in centrals:
            print(
                f"ä¸­æ¢: èµ·ç‚¹={central.start_index}, ç»ˆç‚¹={central.end_index}, "
                f"é«˜ç‚¹={central.high:.2f}, ä½ç‚¹={central.low:.2f}"
            )

            # éªŒè¯ä¸­æ¢èŒƒå›´
            if central.start_index < 0 or central.end_index >= len(df):
                print(f"âŒ ä¸­æ¢ç´¢å¼•è¶Šç•Œ")
                return False

            if central.high <= central.low:
                print(f"âŒ ä¸­æ¢ä»·æ ¼èŒƒå›´æ— æ•ˆ: é«˜={central.high}, ä½={central.low}")
                return False

        print("âœ… ä¸­æ¢è¯†åˆ«æµ‹è¯•é€šè¿‡")
        return True

    def test_central_overlap_condition(self) -> bool:
        """æµ‹è¯•ä¸­æ¢é‡å æ¡ä»¶"""
        print("=== æµ‹è¯•ä¸­æ¢é‡å æ¡ä»¶ ===")

        df = self.create_central_test_data()
        self.processor._merge_k_lines(df)
        self.processor.identify_fractals()
        self.processor.build_strokes()
        centrals = self.processor.build_centrals()

        # éªŒè¯ä¸­æ¢é‡å 
        for central in centrals:
            if len(central.strokes) >= 3:
                # æ£€æŸ¥ç¬”ä¹‹é—´æ˜¯å¦æœ‰é‡å 
                stroke_prices = []
                for stroke in central.strokes:
                    stroke_prices.extend([stroke.start_price, stroke.end_price])

                min_price = min(stroke_prices)
                max_price = max(stroke_prices)

                # éªŒè¯ä¸­æ¢èŒƒå›´åŒ…å«æ‰€æœ‰ç¬”çš„ä»·æ ¼
                if central.low > min_price or central.high < max_price:
                    print(f"âŒ ä¸­æ¢èŒƒå›´ä¸åŒ…å«æ‰€æœ‰ç¬”çš„ä»·æ ¼")
                    return False

        print("âœ… ä¸­æ¢é‡å æ¡ä»¶æµ‹è¯•é€šè¿‡")
        return True

    def test_index_mapping_consistency(self) -> bool:
        """æµ‹è¯•ç´¢å¼•æ˜ å°„ä¸€è‡´æ€§"""
        print("=== æµ‹è¯•ç´¢å¼•æ˜ å°„ä¸€è‡´æ€§ ===")

        df = self.create_central_test_data()

        # è·å–åˆå¹¶åçš„æ•°æ®
        self.processor._merge_k_lines(df)
        merged_df = self.processor.merged_df

        if merged_df is None or merged_df.empty:
            print("âŒ åˆå¹¶æ•°æ®ä¸ºç©º")
            return False

        print(f"åŸå§‹æ•°æ®é•¿åº¦: {len(df)}")
        print(f"åˆå¹¶åæ•°æ®é•¿åº¦: {len(merged_df)}")

        # éªŒè¯ç´¢å¼•æ˜ å°„
        if "original_indices" in merged_df.columns:
            # è®¡ç®—æ˜ å°„çš„å®Œæ•´æ€§
            total_mapped = 0
            for indices in merged_df["original_indices"]:
                total_mapped += len(indices)

            print(f"ç´¢å¼•æ˜ å°„ç»Ÿè®¡: åŸå§‹{len(df)} -> æ˜ å°„{total_mapped}")

            if total_mapped != len(df):
                print("âŒ ç´¢å¼•æ˜ å°„ä¸å®Œæ•´")
                return False

        print("âœ… ç´¢å¼•æ˜ å°„ä¸€è‡´æ€§æµ‹è¯•é€šè¿‡")
        return True

    def test_central_stroke_correlation(self) -> bool:
        """æµ‹è¯•ä¸­æ¢ä¸ç¬”çš„å…³è”"""
        print("=== æµ‹è¯•ä¸­æ¢ä¸ç¬”å…³è” ===")

        df = self.create_central_test_data()
        self.processor._merge_k_lines(df)
        self.processor.identify_fractals()
        self.processor.build_strokes()
        centrals = self.processor.build_centrals()

        for central in centrals:
            # éªŒè¯ä¸­æ¢åŒ…å«çš„ç¬”æ•°é‡
            if len(central.strokes) < 3:
                print(f"âŒ ä¸­æ¢ç¬”æ•°ä¸è¶³: {len(central.strokes)} < 3")
                return False

            # éªŒè¯ç¬”çš„æ—¶é—´é¡ºåº
            for i in range(1, len(central.strokes)):
                prev_stroke = central.strokes[i - 1]
                curr_stroke = central.strokes[i]

                if prev_stroke.end_index > curr_stroke.start_index:
                    print("âŒ ä¸­æ¢å†…ç¬”æ—¶é—´é¡ºåºé”™è¯¯")
                    return False

        print("âœ… ä¸­æ¢ä¸ç¬”å…³è”æµ‹è¯•é€šè¿‡")
        return True

    def test_fractal_index_mapping(self) -> bool:
        """æµ‹è¯•åˆ†å‹ç´¢å¼•æ˜ å°„"""
        print("=== æµ‹è¯•åˆ†å‹ç´¢å¼•æ˜ å°„ ===")

        df = self.create_central_test_data()
        self.processor._merge_k_lines(df)
        fractals = self.processor.identify_fractals()

        # è·å–åˆå¹¶åçš„æ•°æ®
        merged_df = self.processor.merged_df

        if merged_df is None:
            print("âŒ åˆå¹¶æ•°æ®ä¸ºç©º")
            return False

        print(f"åˆ†å‹æ•°é‡: {len(fractals)}")
        print(f"åˆå¹¶åæ•°æ®é•¿åº¦: {len(merged_df)}")

        # éªŒè¯åˆ†å‹ç´¢å¼•åœ¨åˆå¹¶åæ•°æ®èŒƒå›´å†…
        for fractal in fractals:
            if fractal.index < 0 or fractal.index >= len(merged_df):
                print(f"âŒ åˆ†å‹ç´¢å¼•è¶Šç•Œ: {fractal.index} ä¸åœ¨ [0, {len(merged_df)})")
                return False

            # éªŒè¯åˆ†å‹ä»·æ ¼ä¸åˆå¹¶åæ•°æ®åŒ¹é…
            if fractal.type == FractalType.TOP:
                expected_price = merged_df.iloc[fractal.index]["high"]
            else:
                expected_price = merged_df.iloc[fractal.index]["low"]

            if abs(fractal.price - expected_price) > 0.01:
                print(f"âŒ åˆ†å‹ä»·æ ¼ä¸åŒ¹é…: æœŸæœ›{expected_price}, å®é™…{fractal.price}")
                return False

        print("âœ… åˆ†å‹ç´¢å¼•æ˜ å°„æµ‹è¯•é€šè¿‡")
        return True

    def test_visualization_index_mapping(self) -> bool:
        """æµ‹è¯•å¯è§†åŒ–ç´¢å¼•æ˜ å°„"""
        print("=== æµ‹è¯•å¯è§†åŒ–ç´¢å¼•æ˜ å°„ ===")

        df = self.create_central_test_data()

        # è·å–åˆå¹¶åçš„æ•°æ®
        self.processor._merge_k_lines(df)
        merged_df = self.processor.merged_df

        if merged_df is None or merged_df.empty:
            print("âŒ åˆå¹¶æ•°æ®ä¸ºç©º")
            return False

        # åˆ›å»ºç´¢å¼•æ˜ å°„
        original_to_merged_map = {}
        if "original_indices" in merged_df.columns:
            for merged_idx, row in merged_df.iterrows():
                original_indices = row["original_indices"]
                for orig_idx in original_indices:
                    original_to_merged_map[orig_idx] = merged_idx

        print(f"ç´¢å¼•æ˜ å°„æ¡ç›®: {len(original_to_merged_map)}")
        print(f"é¢„æœŸæ˜ å°„: {len(df)} -> {len(merged_df)}")

        # éªŒè¯æ˜ å°„çš„å®Œæ•´æ€§
        for orig_idx in range(len(df)):
            if orig_idx not in original_to_merged_map:
                print(f"âŒ ç¼ºå¤±ç´¢å¼•æ˜ å°„: {orig_idx}")
                return False

        print("âœ… å¯è§†åŒ–ç´¢å¼•æ˜ å°„æµ‹è¯•é€šè¿‡")
        return True

    def test_central_boundaries(self) -> bool:
        """æµ‹è¯•ä¸­æ¢è¾¹ç•Œæ¡ä»¶"""
        print("=== æµ‹è¯•ä¸­æ¢è¾¹ç•Œæ¡ä»¶ ===")

        # åˆ›å»ºè¾¹ç•Œæµ‹è¯•æ•°æ®
        boundary_data = {
            "time_key": pd.date_range("2024-01-01", periods=10, freq="D"),
            "open": [10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0],
            "high": [11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0],
            "low": [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0],
            "close": [10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5],
        }
        df = pd.DataFrame(boundary_data)

        self.processor._merge_k_lines(df)
        self.processor.identify_fractals()
        self.processor.build_strokes()
        centrals = self.processor.build_centrals()

        # è¾¹ç•Œæƒ…å†µéªŒè¯
        if len(centrals) > 0:
            central = centrals[0]
            print(f"è¾¹ç•Œä¸­æ¢: é«˜ç‚¹={central.high}, ä½ç‚¹={central.low}")

            if central.high == central.low:
                print("âš ï¸  ä¸­æ¢ä»·æ ¼èŒƒå›´ä¸ºé›¶")

        print("âœ… ä¸­æ¢è¾¹ç•Œæ¡ä»¶æµ‹è¯•é€šè¿‡")
        return True

    def test_complex_central_patterns(self) -> bool:
        """æµ‹è¯•å¤æ‚ä¸­æ¢æ¨¡å¼"""
        print("=== æµ‹è¯•å¤æ‚ä¸­æ¢æ¨¡å¼ ===")

        # åˆ›å»ºå¤æ‚ä¸­æ¢æ•°æ®
        complex_data = {
            "time_key": pd.date_range("2024-01-01", periods=50, freq="D"),
            "open": [],
            "high": [],
            "low": [],
            "close": [],
        }

        # æ¨¡æ‹Ÿå¤æ‚éœ‡è¡èµ°åŠ¿
        for i in range(50):
            base = 10 + (i % 10) * 0.1
            complex_data["open"].append(base)
            complex_data["high"].append(base + 1.0)
            complex_data["low"].append(base - 1.0)
            complex_data["close"].append(base + 0.5)

        df = pd.DataFrame(complex_data)

        self.processor._merge_k_lines(df)
        self.processor.identify_fractals()
        self.processor.build_strokes()
        centrals = self.processor.build_centrals()

        print(f"å¤æ‚æ•°æ®ä¸­è¯†åˆ«å‡ºçš„ä¸­æ¢: {len(centrals)}")

        # éªŒè¯ä¸­æ¢çš„åˆç†æ€§
        for central in centrals:
            if central.end_index - central.start_index < 2:
                print("âŒ ä¸­æ¢åŒºé—´è¿‡å°")
                return False

        print("âœ… å¤æ‚ä¸­æ¢æ¨¡å¼æµ‹è¯•é€šè¿‡")
        return True

    def run_all_tests(self) -> dict:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹è¿è¡Œç¼ è®ºä¸­æ¢å’Œç´¢å¼•æ˜ å°„æµ‹è¯•...\n")

        results = {
            "central_identification": self.test_central_identification(),
            "central_overlap_condition": self.test_central_overlap_condition(),
            "index_mapping_consistency": self.test_index_mapping_consistency(),
            "central_stroke_correlation": self.test_central_stroke_correlation(),
            "fractal_index_mapping": self.test_fractal_index_mapping(),
            "visualization_index_mapping": self.test_visualization_index_mapping(),
            "central_boundaries": self.test_central_boundaries(),
            "complex_central_patterns": self.test_complex_central_patterns(),
        }

        print("\n" + "=" * 60)
        print("ğŸ“Š æµ‹è¯•æ€»ç»“:")
        passed = sum(results.values())
        total = len(results)
        print(f"é€šè¿‡: {passed}/{total}")

        for test_name, result in results.items():
            status = "âœ…" if result else "âŒ"
            print(f"{status} {test_name}")

        return results


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    tester = TestChanlunCentralMapping()
    results = tester.run_all_tests()

    if all(results.values()):
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°")

    return results


if __name__ == "__main__":
    main()
